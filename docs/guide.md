# CFB Model Guide â€” Single Source of Truth

**Last Updated**: 2025-12-05  
**Status**: Active (V2 Workflow Aligned)

This is the canonical entry point for all project documentation. All other docs link here or are linked from here.

---

## ğŸ¯ V2 Experimentation Workflow (NEW)

**Status**: Implementation starting Week 1 (Dec 9, 2025)

The project follows a **4-phase V2 workflow** for all modeling work:

1. **Phase 1: Baseline Establishment** â†’ Ridge regression with minimal features
2. **Phase 2: Feature Engineering & Selection** â†’ Test features with baseline model
3. **Phase 3: Model Selection** â†’ Test complex models with promot features
4. **Phase 4: Deployment & Monitoring** â†’ Champion Model to production

**Key Documents**:

- [V2 Workflow](process/experimentation_workflow.md) â€” Full 4-phase process
- [12-Week Plan](process/12_week_implementation_plan.md) â€” Week-by-week roadmap
- [Promotion Framework](process/promotion_framework.md) â€” 5-gate rigor system
- [V2 Baseline](modeling/baseline.md) â€” Ridge regression philosophy

---

## ğŸš€ Quick Start

### First Time Here?

1. **Humans**: Read [Getting Started](#getting-started) below
2. **AI Assistants**: Start with `AGENTS.md` (repo root) for session protocols, then return here for domain knowledge

### I Need To...

| Task                           | Go To                                                                                             |
| ------------------------------ | ------------------------------------------------------------------------------------------------- |
| **Understand V2 workflow**     | [V2 Workflow](process/experimentation_workflow.md)                                                |
| **See 12-week plan**           | [12-Week Plan](process/12_week_implementation_plan.md)                                            |
| Set up development environment | [Getting Started](#getting-started)                                                               |
| Run the weekly pipeline        | [Weekly Pipeline](ops/weekly_pipeline.md)                                                         |
| Understand current baseline    | [V2 Baseline](modeling/baseline.md)                                                               |
| Run an experiment              | [Experiments](experiments/index.md) + [Promotion Framework](process/promotion_framework.md)       |
| Add a new feature              | [Feature Engineering](modeling/features.md) + [Feature Registry](project_org/feature_registry.md) |
| Review betting policy          | [Betting Policy](modeling/betting_policy.md)                                                      |
| Check recent decisions         | [Decision Log](decisions/decision_log.md)                                                         |
| Troubleshoot data issues       | [Data & Paths](ops/data_paths.md) + [Data Quality](ops/data_quality.md)                           |
| Monitor model performance      | [Monitoring Dashboard](ops/monitoring.md)                                                         |
| Rollback a model               | [Rollback SOP](ops/rollback_sop.md)                                                               |

---

## ğŸ“– Documentation Structure

### Process & Workflow

**How we work: development standards, ML workflow, AI collaboration**

- [ML Workflow](process/ml_workflow.md) â€” Train/Test/Deploy split, model versioning
- [Development Standards](process/development_standards.md) â€” Code style, testing, documentation
- [Experimentation Workflow](process/experimentation_workflow.md) - The V2 process for all modeling.
- [Data Quality Validation Workflow](process/data_quality_workflow.md) - Automated checks for data integrity.
- [Opponent-Adjustment Analysis Workflow](process/adjustment_analysis_workflow.md) - Process for validating adjustment iterations.
- [Session Checklists](process/checklists.md) â€” Kickoff and closing workflows
- [Session Logs](../session_logs/) â€” Chronological development history

### Data Pipeline Flow

1.  **Raw Ingestion** â†’ Fetch from CollegeFootballData.com API into local raw storage.
2.  **Aggregation** â†’ Run `scripts/pipeline/run_pipeline_generic.py` to transform raw plays into aggregated `byplay`, `drives`, and `team_game` datasets in processed storage.
3.  **Validation** â†’ Run `scripts/pipeline/validate_data.py` to verify the quality and integrity of the aggregated data.
4.  **Feature Engineering** â†’ Generate point-in-time, opponent-adjusted features for modeling (`team_week_adj`).
5.  **Modeling** â†’ Train models using the V2 Experimentation Workflow.
6.  **Inference** â†’ Derive spreads/totals, calculate edges, and apply betting policy.

### Modeling & Features

**What we build: models, features, evaluation criteria**

- [Modeling Baseline](modeling/baseline.md) â€” Current production architecture
- [Feature Catalog](modeling/features.md) â€” All engineered features and definitions
- [Generated Feature Dictionary](modeling/feature_dictionary.md) - Auto-generated dictionary of all available features.
- [Feature Registry](project_org/feature_registry.md) â€” Active feature groups (Hydra configs)
- [Experiments Index](experiments/index.md) â€” Experiment tracking and results
- [Betting Policy](modeling/betting_policy.md) â€” Unit sizing, exposure rules, risk management
- [Calibration](modeling/calibration.md) â€” Model calibration and bias correction

### Operations

**How we run: pipelines, deployment, data management, monitoring**

- [Weekly Pipeline](ops/weekly_pipeline.md) â€” 5-step production workflow
- [Production Deployment](ops/production_deployment.md) â€” Champion Model deployment (Phase 4)
- **[Monitoring Dashboard](ops/monitoring.md)** â€” **NEW:** Streamlit dashboard for performance tracking
- **[Rollback SOP](ops/rollback_sop.md)** â€” **NEW:** Model rollback procedure
- **[Data Quality](ops/data_quality.md)** â€” **NEW:** 3-layer validation system
- [Data Paths & Storage](ops/data_paths.md) â€” External drive configuration, partitioning
- [MLflow Usage](ops/mlflow_mcp.md) â€” Experiment tracking, model registry

### Planning & Roadmap

**Where we're going: roadmap, active initiatives**

- [Project Roadmap](planning/roadmap.md) â€” High-level strategy and timeline
- [Active Initiatives](planning/) â€” Current research and development tracks
- [Points-For Model (Archive)](archive/points_for_model.md) â€” Historical: rejected architecture

### Research

**Exploratory work: PRDs, prototypes, investigations**

- [Probabilistic Power Ratings](research/ppr_prd.md) â€” Bayesian team ratings (active research)
- [Research Archive](research/archive/) â€” Completed or abandoned investigations

### Decisions

**Why we chose: decision history and rationale**

- [Decision Log](decisions/decision_log.md) â€” All major modeling and architecture decisions
- [Open Decisions (Archive)](archive/open_decisions.md) â€” Historical unresolved/planning decisions

---

## ğŸ¯ Getting Started

### Prerequisites

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) for dependency management
- [Docker](https://www.docker.com/) for MLflow and dashboard services
- CollegeFootballData.com API key
- External storage drive (for data)

### Installation

```bash
# Clone repository
git clone https://github.com/connorkitchings/cfb_model.git
cd cfb_model

# Install dependencies
uv sync --extra dev

# Activate environment
source .venv/bin/activate

# Configure environment
cp .env.example .env
# Edit .env and set:
#   CFB_MODEL_DATA_ROOT='/path/to/external/drive'
#   CFBD_API_KEY='your_api_key'

# Verify installation
uv run pytest -q
uv run ruff check .
```

### Essential Environment Variables

**CRITICAL**: All raw and processed data lives on an external drive, NOT in the project directory.

```bash
# Required
CFB_MODEL_DATA_ROOT='/Volumes/CK SSD/Coding Projects/cfb_model/'  # External drive path
CFBD_API_KEY='your_api_key_here'                                   # API access

# Optional
MLFLOW_TRACKING_URI='file://./artifacts/mlruns'                    # MLflow storage
```

**Always verify before ANY data operation**:

```python
import os
from pathlib import Path

data_root = os.getenv("CFB_MODEL_DATA_ROOT")
assert data_root and Path(data_root).exists(), f"Data root not accessible: {data_root}"
```

---

## ğŸ—ï¸ Project Architecture

### Directory Structure

```
cfb_model/
â”œâ”€â”€ src/                      # Library code
â”‚   â”œâ”€â”€ config/               # Path configuration, constants
â”‚   â”œâ”€â”€ data/                 # Data ingestion and access
â”‚   â”œâ”€â”€ features/             # Feature engineering pipeline
â”‚   â”œâ”€â”€ models/               # Training, evaluation, prediction
â”‚   â”œâ”€â”€ inference/            # Production inference
â”‚   â””â”€â”€ utils/                # MLflow, storage utilities
â”œâ”€â”€ scripts/                  # CLI entry points
â”‚   â”œâ”€â”€ pipeline/             # Production pipeline scripts
â”‚   â”œâ”€â”€ analysis/             # Analysis and validation
â”‚   â”œâ”€â”€ experiments/          # Research and optimization
â”‚   â””â”€â”€ cli.py                # Main CLI
â”œâ”€â”€ docs/                     # Documentation (you are here!)
â”‚   â”œâ”€â”€ guide.md              # This file (hub)
â”‚   â”œâ”€â”€ process/              # How we work
â”‚   â”œâ”€â”€ modeling/             # What we build
â”‚   â”œâ”€â”€ ops/                  # How we run
â”‚   â”œâ”€â”€ planning/             # Where we're going
â”‚   â”œâ”€â”€ research/             # Exploratory work
â”‚   â”œâ”€â”€ decisions/            # Why we chose
â”‚   â”œâ”€â”€ experiments/          # Experiment tracking
â”‚   â””â”€â”€ archive/              # Historical/obsolete docs
â”œâ”€â”€ conf/                     # Hydra configuration
â”‚   â”œâ”€â”€ config.yaml           # Top-level defaults
â”‚   â”œâ”€â”€ model/                # Model configs
â”‚   â”œâ”€â”€ features/             # Feature set definitions
â”‚   â”œâ”€â”€ experiment/           # Pre-packaged experiments
â”‚   â””â”€â”€ weekly_bets/          # Betting policy configs
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ artifacts/                # V2 outputs (see docs/ops/artifacts_structure.md)
â”‚   â”œâ”€â”€ mlruns/               # MLflow tracking
â”‚   â”œâ”€â”€ models/               # Trained models (baseline, candidates, production)
â”‚   â”œâ”€â”€ experiments/          # Experiment outputs (metrics, plots)
â”‚   â”œâ”€â”€ production/           # Weekly predictions, scoring, monitoring
â”‚   â””â”€â”€ validation/           # Data quality, walk-forward validation
â”œâ”€â”€ archive/                  # Unused scripts, configs, notebooks
â”œâ”€â”€ session_logs/             # Development session history
â”œâ”€â”€ AGENTS.md                 # Universal AI assistant entry point
â”œâ”€â”€ CLAUDE.md                 # Redirect to AGENTS.md
â””â”€â”€ README.md                 # Project overview
```

### Data Pipeline Flow

1. **Raw Ingestion** â†’ Fetch from CollegeFootballData.com API
2. **Aggregation** â†’ Plays â†’ Drives â†’ Team-Game â†’ Team-Season
3. **Feature Engineering** â†’ Opponent adjustment, recency weighting, interactions
4. **Modeling** â†’ Points-For architecture (predict home/away scores)
5. **Inference** â†’ Derive spreads/totals, calculate edges, apply policy

See [Weekly Pipeline](ops/weekly_pipeline.md) for production workflow.

---

## ğŸ² Current Production Models

**As of December 2025 (v5 models)**:

| Model                    | Target | Architecture                | Features    | Performance (2024 Test)    |
| ------------------------ | ------ | --------------------------- | ----------- | -------------------------- |
| `spread_catboost_ppr` v5 | Spread | CatBoost ensemble (5 seeds) | ppr_v1      | 52.2% hit rate (226-207-8) |
| `totals_xgboost_ppr` v5  | Total  | XGBoost ensemble (5 seeds)  | standard_v1 | 58.6% hit rate (112-79-4)  |

**Key Configuration**:

- Train Years: 2019, 2021, 2022, 2023 (exclude 2020 COVID year)
- Test Year: 2024 (locked holdout)
- Deploy Year: 2025 (live production)
- Adjustment Iteration: 2 (opponent adjustment depth)
- Thresholds: 5.0 (spread), 7.5 (total)

See [Modeling Baseline](modeling/baseline.md) for full details.

---

## ğŸ”§ Common Workflows

### Weekly Production Pipeline

```bash
# 1. Ingest latest week data
uv run python scripts/pipeline/cache_weekly_stats.py --year 2025

# 2. Generate predictions
uv run python scripts/pipeline/generate_weekly_bets.py --year 2025 --week 16

# 3. After games: Score performance
uv run python scripts/pipeline/score_weekly_bets.py --year 2025 --week 16
```

### Training a New Model

```bash
# Train with Hydra experiment config
PYTHONPATH=. uv run python src/models/train_model.py experiment=spread_catboost_ppr_v1

# Hyperparameter optimization
PYTHONPATH=. uv run python src/models/train_model.py mode=optimize

# Debug configuration
PYTHONPATH=. uv run python src/models/train_model.py --cfg job --resolve
```

### Running Analysis

```bash
# Verify baseline performance
uv run python scripts/analysis/verify_baseline_2024.py

# Threshold optimization
uv run python scripts/analysis/optimize_thresholds.py --year 2024

# SHAP feature importance
uv run python scripts/analysis/run_shap_analysis.py
```

### Health Checks

```bash
# Format and lint
uv run ruff format . && uv run ruff check .

# Run tests
uv run pytest -q

# Build documentation
mkdocs build --quiet
```

---

## ğŸ“Š Key Performance Metrics

**Definitions** (see [Modeling Baseline](modeling/baseline.md)):

- **Hit Rate**: Percentage of correct predictions against the spread/total
- **Breakeven**: 52.4% hit rate required to profit at -110 odds
- **ROI**: Return on investment assuming -110 juice
- **Volume**: Number of bets meeting threshold criteria

**Current Status (2025 Live Performance)**:

- Spread: 50.1% hit rate (237-236-11) â€” Below breakeven âš ï¸
- Total: 51.4% hit rate (95-90-0) â€” Below breakeven âš ï¸

See [Experiments Index](experiments/index.md) for detailed tracking.

---

## ğŸš¨ Common Pitfalls

### 1. Data Not on External Drive

**Problem**: Script creates `./data/` in project root
**Solution**: Always load `CFB_MODEL_DATA_ROOT` from env; fail loudly if not set

### 2. Train/Test Data Leakage

**Problem**: Including test year in training data
**Solution**: Use locked split: Train on 2019/2021-2023, Test on 2024, Deploy on 2025

### 3. Hardcoded Paths

**Problem**: Using `/Users/...` or `./data/`
**Solution**: Always use `os.getenv("CFB_MODEL_DATA_ROOT")`

### 4. Modifying Betting Policy in Code

**Problem**: Changing unit sizing or exposure rules programmatically
**Solution**: Only read and apply policy from [Betting Policy](modeling/betting_policy.md)

See [Data Paths](ops/data_paths.md) for full troubleshooting.

---

## ğŸ“š Learning Paths

### New Developer

1. Read this guide â†’ [Getting Started](#getting-started)
2. Review [Development Standards](process/development_standards.md)
3. Explore [Modeling Baseline](modeling/baseline.md)
4. Try running [Weekly Pipeline](ops/weekly_pipeline.md) on historical data

### Data Scientist / Researcher

1. Start with [Modeling Baseline](modeling/baseline.md) and [Feature Catalog](modeling/features.md)
2. Review [Experiments Index](experiments/index.md) for current state
3. Check [Decision Log](decisions/decision_log.md) for recent changes
4. Read [ML Workflow](process/ml_workflow.md) for train/test protocols

### AI Assistant

1. Read `AGENTS.md` for session protocols
2. Review this guide for navigation
3. Check [Session Checklists](process/checklists.md) for workflows
4. Always verify data root before ANY data operations

---

## ğŸ”— External Resources

- [Project Repository](https://github.com/connorkitchings/cfb_model)
- [CollegeFootballData.com API](https://collegefootballdata.com/exporter)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Hydra Configuration](https://hydra.cc/docs/intro/)

---

## ğŸ“ Changelog

### 2025-12-04: Repository Reorganization

- Created `docs/guide.md` as single source of truth
- Reorganized docs into process/, modeling/, ops/, planning/, research/ buckets
- Created archive/ for unused scripts and configs
- Archived legacy decision log
- Purged stale artifacts (preserved 2025 Week 15 predictions)

### 2025-12-03: ML Workflow Standardization

- Fixed train/test split (removed 2024 from training)
- Retrained v5 models with proper split
- Created `docs/project_org/ml_workflow.md`

### 2025-12-01: PPR Prototype

- Implemented Probabilistic Power Ratings with Gaussian Random Walk
- Created backtest script for walk-forward validation

---

**Questions or issues?** Check the [Decision Log](decisions/decision_log.md) or create a session log entry.
