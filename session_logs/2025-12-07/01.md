# Dev Session Log â€” 2025-12-07

**Session ID:** 01
**Date:** 2025-12-07
**Duration:** ~2 hours
**Focus Area:** V2 Workflow (Phase 1-4 + Tuning)

---

## 1. Session Summary

- **Key Outcomes**:
  1.  **Phase 1 Cleanup**: Committed baseline files (ROI -3.35%).
  2.  **Phase 2 Features**: Promoted `opponent_adjusted_v1` (ROI -0.97%).
  3.  **Data Quality**: Implemented validation suite and fixed a 2024 data bug (filtered incomplete games).
  4.  **Phase 3 Model Selection**: Tested CatBoost (-1.76%) and XGBoost (-0.71%). Failed promotion target.
  5.  **Phase 4 Ensembling**: Tested Linear+XGBoost (-3.09%). Failed.
  6.  **Phase 3.5 Tuning**: Tuned XGBoost with Optuna (-1.23%). Failed.

## 2. Blockers and Learnings

- **Linear is Tough**: The `opponent_adjusted_v1` linear model is incredibly robust. Complex models (XGBoost) struggle to generalize better despite lower training error.
- **Metric Sensitivity**: Tuning for ROI is noisy. Tuning for RMSE doesn't guarantee ROI.
- **Data Quality**: Validation scripts proved their worth immediately.

## 3. Next Steps

- **Investigate Stacking**: A meta-learner might combine models better than averaging.
- **New Features**: We need better signal (recency weighting, interaction terms) rather than just better models.
