# Dev Session Log — 2025-12-07

**Session ID:** 03
**Date:** 2025-12-07
**Duration:** ~1.5 hours
**Focus Area:** V2 Feature Engineering (Interactions) & Critical Bug Fix

---

## 1. Session Summary

- **Task Completed**: V2 Phase 2 Interaction Features Experiment & Data Pipeline Repair
- **Key Outcomes**:
  1.  **Critical Bug Fix**: Identified and fixed a massive data duplication bug in `src/features/v2_recency.py`.
      -   **Issue**: `load_v2_recency_data` was returning *all* 5 iterations of opponent adjustment for every game, causing a 5x explosion in dataset size (18k rows vs 3k expected) and invalidating previous absolute metrics.
      -   **Fix**: Added a filter to keep only the final iteration.
  2.  **Champion Re-Validation**: Retrained the Recency Linear Champion on the corrected dataset.
      -   **Result**: **ROI +0.52%** | Hit Rate 52.65% (2024 Test).
      -   **Significance**: This confirms the model is **profitable** on the holdout set, exceeding the previous estimate of -0.15%.
  3.  **Interaction Experiment (V2-002)**: Implemented and tested EPA/SR interaction terms.
      -   **Config**: `conf/features/interaction_v1.yaml` (Off x Def interactions).
      -   **Result**: ROI -0.26% | Hit Rate 52.24%.
      -   **Outcome**: **REJECTED**. Interactions degraded performance by ~0.8% ROI compared to the clean champion.
  4.  **Pipeline Refactor**: Updated `src/train.py` to support dynamic feature selection (`select_features`) for all model types, enabling declarative interaction generation in Hydra configs.

## 2. Blockers and Learnings

-   **Blockers**: None.
-   **Learnings**:
    -   **Data Quality is Paramount**: The duplication bug was subtle but impactful. Always verify row counts against expected game counts (~800-900/season).
    -   **Simplicity Persists**: Adding "logical" interactions (Offense x Defense) failed to improve upon the simple additive Recency model. The linear model likely captures the main signal (Offense strength - Defense strength) sufficiently well.
    -   **Profitability Achieved**: We have a profitable baseline (+0.52% ROI). Future experiments have a high bar to clear.

## 3. Next Steps

-   **Immediate**:
    -   Explore **Matchup-Specific Features** (e.g., Rushing Offense vs Rushing Defense) to see if targeted interactions work better than broad ones.
    -   Begin **Totals Modeling** (untapped market).
-   **Documentation**: Ensure `feature_registry.md` reflects the "Rejected" status of interactions.

## 4. Final Health Check

-   `uv run ruff check .`: ✅ Passed
-   `uv run pytest`: ✅ Passed
