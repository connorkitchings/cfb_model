---
date: 2025-11-18
branch: main
task: [IMPL-task:RECENCY-MODELS] - Expand recency features and evaluate new model families
---

## Wins

- Extended `aggregate_team_season` + `cache_weekly_stats.py` to emit pace/tempo stats with 4/3/2/1 recency weights and regenerated caches for 2019-2025 so training and prediction seasons stay consistent.
- Added LightGBM/CatBoost configs + Optuna sweeps; captured latest runs under `artifacts/mlruns/539192925932813498` (best total CatBoost run `00cec97ec8774a3186dac79ee88b0335` at RMSE 17.20 / MAE 13.53).
- Created the expected `outputs/prototypes/points_for_training_slice_2023_filtered.csv` fixture so the slice regression tests pass and confirmed health checks: `uv run ruff format .`, `uv run ruff check .`, `uv run pytest tests/ -v --tb=short`, `uv run mkdocs build --quiet`.

## Blockers

- Full walk-forward validation across 2019-2024 still struggles with CLI timeouts/noise; restricting to 2024 works but a longer-term solution (chunking years or trimming logging) is needed before rerunning the entire historical set.

## Artifacts & Links

- MLflow: experiment `539192925932813498` (see runs `838fc37c2b9f46238800eb9bbeff20d6`, `7f48fbb590dd438a8de9e43aa1ba55c6`, `00cec97ec8774a3186dac79ee88b0335`).
- Cache outputs refreshed under `/Volumes/CK SSD/Coding Projects/cfb_model/processed/team_week_adj/iteration=4/year=20XX/`.
- Tests/logs: `outputs/prototypes/points_for_training_slice_2023_filtered.csv` fixture for regression tests.

## Handoff

- Stopping Point: Recency + tempo features are live in the caches, LightGBM/CatBoost sweeps have initial metrics, and all health checks pass locally.
- Next Immediate Task: Prototype exponential/half-life weighting and mixed offense/defense adjustment depths, then rerun sweeps and walk-forward validation with logging trimmed for long horizons.
- Known Issues: Walk-forward validation is still noisy/time-consuming, and CatBoost totals remain ~0.3 RMSE behind the ensemble baseline.
- Next Session Context: Start from the refreshed caches, use the existing Hydra configs (`conf/model/*_{lightgbm,catboost}.yaml`) for new sweeps, and capture MLflow run IDs for any experiments that beat the ensemble.
