---
date: 2025-09-29
branch: main
task: [IMPL-task:model-improve-and-calibrate] - Add features, implement no-leak calibration, lock thresholds, update docs
---

## Wins

- Implemented quick-win feature updates:
  - Added pace/opportunity features for totals (plays_per_game, drives_per_game, avg_scoring_opps_per_game), excluding timing metrics
  - Added neutral_site and robust same_conference fallback (from conferences → conference_game → 0)
- Built training-derived, week-of-season calibration utilities (no in-season leakage)
  - scripts/calibrate_and_thresholds.py supports train/holdout mode and recomputes calibrated bets and hit rates
  - src/cfb_model/models/calibration.py provides bias computation and application helpers
- Retrained Ridge baseline and ran full-season tests
  - 2024 holdout (post model fixes) produced 100/187 = 0.535 prior to calibration
  - Ran 2019/2021/2022/2023 to produce scored training seasons for calibration
- Calibrated thresholds (train years → holdout 2024)
  - Spreads (6.0): 54.9% hit (184 picks)
  - Totals (6.0): 55.3% hit (152 picks)
- Locked default thresholds to 6.0/6.0; updated CLI defaults, weekly pipeline, baseline docs, and WARP guidance

## Blockers

- SHAP explanations threw dtype errors during weekly generation; fixed by coercing SHAP values to numeric
- Feature mismatch (same_conference) between training and prediction; resolved by deriving in both paths
- Calibration sweeps initially counted uncalibrated win flags; fixed by computing wins from actuals vs recomputed calibrated bets

## Artifacts & Links

- Calibration
  - reports/calibration/spread_weekly_bias_from_training.csv
  - reports/calibration/total_weekly_bias_from_training.csv
  - reports/calibration/holdout_spread_threshold_sweep_calibrated.csv
  - reports/calibration/holdout_total_threshold_sweep_calibrated.csv
  - reports/calibration/holdout_season_calibrated_predictions.csv
- Decisions
  - [PRD-decision:2025-09-29] Calibrated Edge Thresholds Locked to 6.0/6.0 (docs/decisions/decision_log.md)
- Code Changes (highlights)
  - Updated feature selection (src/cfb_model/models/features.py)
  - Weekly generator parity fixes + SHAP numeric (src/cfb_model/scripts/generate_weekly_bets_clean.py)
  - CLI defaults (scripts/cli.py)
  - Calibration utilities (src/cfb_model/models/calibration.py; scripts/calibrate_and_thresholds.py)

## Handoff

- Stopping Point: Thresholds updated and documentation revised; calibration artifacts generated; season backfills completed for training years.
- Next Immediate Task:
  - Optionally wire calibration application into run-season CLI (feature flag) so weekly reports reflect calibrated picks directly
  - Add simple hyperparameter search (Ridge/ElasticNet) and evaluate against calibrated thresholds
- Known Issues:
  - Some historical weeks (15/16) have limited or missing scored data and are skipped; acceptable for current analysis
- Next Session Context:
  - Use reports/calibration/holdout_*_threshold_sweep_calibrated.csv to confirm final threshold choices
  - If pursuing modeling variants, use scripts/model_improvement_experiments.py to baseline alternatives and compare CV RMSE
