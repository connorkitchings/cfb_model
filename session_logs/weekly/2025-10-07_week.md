# Session Log - Week of 2025-10-07

## Overview
- **Week**: 2025-10-07 to 2025-10-13
- **Sessions**: 7 sessions across 4 days
- **Dates**: 2025-10-07, 2025-10-09, 2025-10-10, 2025-10-11

---

## Daily Sessions

### 2025-10-07

#### Session 01

---
date: 2025-10-07
branch: main
task: [IMPL-task:34] - Systematic feature selection
---

## Wins

- Executed a full, multi-stage feature selection experiment to identify a smaller, more predictive feature set.
- Successfully identified and fixed a recurring data pipeline bug where processed data was not found by downstream scripts.
- Traced the pipeline issue to its root causes: incorrect `data_root` pathing and a mismatch between partitioned data writing and monolithic data reading logic.
- Refactored the data loading logic in `src/cfb_model/models/features.py` to be compatible with the weekly partitioned data, making the pipeline more robust.
- Confirmed that reverting to the full feature set restored the model's higher performance (54.6% hit rate).

## Blockers

- The feature selection experiment, while successful in reducing feature count, resulted in a model with a lower hit rate (52.3%) than the baseline.
- The debugging process was prolonged due to a layered data issue that required fixing both the data ingestion and data loading steps.

## Artifacts & Links

- Decisions: `[PRD-decision:2025-10-07]` - Reverted the feature selection experiment.
- Learnings: `[KB:FeatureSelectionValidation]` - Feature selection is not a guaranteed improvement and must be validated.

## Handoff

- **Stopping Point**: The feature selection experiment is complete. The codebase has been reverted to its previous, higher-performing state. All data pipeline issues discovered during the process have been fixed.
- **Next Immediate Task**: Re-evaluate the model improvement strategy. Since feature selection was not successful, the next best step is likely to focus on the other high-priority items from the backlog, such as further variance reduction techniques or exploring alternative model architectures like XGBoost.
- **Known Issues**: None. The project is in a stable and profitable state.
- **Next Session Context**: The systematic feature selection path has been explored and determined to be less effective than the current full-feature approach. The project is ready to explore other avenues for performance improvement.


---

#### Session 02

---
date: 2025-10-07
branch: main
task: IMPL-ops:2025-10-07 - Week 6 scoring and review email corrections
---

## Wins

- Ingested Week 6 games and plays; confirmed raw week-partitioned results under `raw/games/year=2025/week=6/data.csv`.
- Fixed spread scoring logic so away bets win when home favorites fail to cover (e.g., USF -28.5 vs Charlotte, margin 28 → away wins).
- Resolved data source mismatch by reading week-partitioned raw games (project root with `data_type=raw`) instead of `data/raw/games/year=YYYY/data.csv`.
- Corrected email time handling: localized report Date/Time as ET (no UTC conversion).
- Updated weekly review email columns: Date, Time, Game, Line, Model Prediction, Bet, Final Score, Final Result, Bet Result.
- Added validation to ensure scored bet counts match the original report (7 spread, 3 totals); confirmed final results: spreads 6-1, totals 2-1.
- Sent test and production review emails for Week 6 successfully.

## Blockers

- Initial duplicate rows due to merging bets against non-deduped or aggregated games data.
- Misinterpreted API responses as incomplete; root cause was reading the wrong file path (aggregated vs week-partitioned raw).
- Timezone misinterpretation (UTC conversion) led to incorrect email times; fixed by localizing to ET.

## Artifacts & Links

- New: `score_fresh.py` (fresh scoring utility from scratch)
- New: `validate_scoring.py` (bet-count verification and diagnostics)
- New: `scripts/add_game_id_to_report.py` (game_id backfill for older reports)
- Updated: `scripts/publish_review.py` (ET localization, new bet row columns)
- Updated: `templates/email_last_week_review.html` (render requested columns)
- Updated: `scripts/score_weekly_picks.py` (clarify/avoid merge duplicates when applicable)
- Reports: `reports/2025/CFB_week6_bets.csv`, `reports/2025/CFB_week6_bets_scored.csv`
- Raw results: `raw/games/year=2025/week=6/data.csv`
- Docs updated: `docs/operations/weekly_pipeline.md`, `docs/decisions/decision_log.md`

## Handoff

- Stopping Point: Week 6 scoring finalized and review emails sent.
- Next Immediate Task: Prepare next week's bets email (Week 7) and ensure models/2025 → 2024 symlink remains valid.
- Known Issues: None active after corrections; retain `score_fresh.py` as a fallback if `score_weekly_picks.py` encounters merge anomalies.
- Next Session Context: Use the updated runbook notes (ET time handling, week-partitioned raw games) and the validation script to verify counts before sending.


---

#### Session 03

---
date: 2025-10-07
branch: main
task: [IMPL-task:EMAIL-IMPROVEMENTS] - Implement various email improvements including ROI calculation, moneyline consideration, and logo integration.
---

## Wins

- Implemented a safety check in `publish_picks.py` to prevent sending emails if betting line data is missing for recommended bets.
- Fixed the root cause of missing betting line data by removing faulty skipping logic in `BettingLinesIngester`.
- Corrected indentation errors in `publish_picks.py` introduced during previous modifications.
- Modified `generate_weekly_bets_clean.py` to include `home_moneyline` and `away_moneyline` in the weekly report CSV.
- Updated `publish_picks.py` to remove ROI calculation from the email and only display hit rates and counts.
- Implemented logic to add a `consider_moneyline` column to the spreads table in the email, marking bets where the model predicts a different team is favored by more than 3 points.
- Integrated team logos into the "Game" column of the email tables (spreads, totals, full schedule) by embedding them as `cid` attachments.
- Successfully ran the weekly pipeline for Week 7, confirming all fixes and improvements.
- Resolved all linting errors (`E712`, `I001`, `W293`, `N806`, `F821`, `F841`) across multiple files (`debug_week6.py`, `score_fresh.py`, `validate_scoring.py`, `scripts/run_feature_selection.py`, `scripts/publish_picks.py`, `scripts/publish_review.py`).

## Blockers

- Initial `Permission denied` error when running `run_weekly_pipeline.sh` (resolved by running commands individually).
- `ValueError: No cached weekly adjusted stats found` due to `preagg` not being run for the latest week (resolved by running `preagg` and then `cache_weekly_stats`).
- `IndentationError` in `publish_picks.py` after adding the betting line safety check (resolved by replacing the entire `main` function with a correctly indented version).
- Difficulty in debugging ROI calculation due to hardcoded odds and lack of moneyline data in reports (resolved by adding moneyline data to reports and simplifying ROI to hit rate only).
- Persistent linting errors (`E712`, `N806`, `F821`) requiring multiple iterations of fixes and health checks.

## Artifacts & Links

- Learnings: [KB:ToolingIndentationIssues], [KB:PipelineDependency], [KB:EmailImageEmbedding], [KB:LintingIteration]
- Code Health: All checks passed (ruff check, ruff format, pytest, mkdocs build).

## Handoff

- Stopping Point: All requested email improvements have been implemented and verified. The weekly pipeline is fully functional and robust.
- Next Immediate Task: None, as the session is concluding. The pipeline is ready for the next weekly run.
- Known Issues: None.
- Next Session Context: The project is in a stable state with an enhanced email reporting system.


---

### 2025-10-09

#### Session 01

---
date: 2025-10-09
branch: main
task: [PIPELINE-REFACTOR-EXEC] - Execute full-season runs and refactor the data pipeline.
---

## Wins

- Successfully ran the full hybrid-model pipeline for the 2024 season and the first 6 weeks of the 2025 season, generating and scoring all bets.
- Identified and fixed multiple critical bugs in the prediction and analysis scripts related to feature mismatches, index length errors, and incorrect hit rate calculations.
- Refactored the weekly feature caching pipeline into a more modular, two-stage process (non-adjusted aggregation, then opponent adjustment) as requested.
- Confirmed the 2024 totals model hit rate is ~63%, validating user expectations.

## Blockers

- The session was repeatedly blocked by bugs in the prediction and analysis scripts, which required several iterations of debugging and patching. These were all eventually resolved.

## Artifacts & Links

- Learnings:
  - `[KB:PrecomputationModularity]` - Splitting a complex precomputation step into modular stages improves maintainability and makes it easier to experiment with individual parts of the pipeline.
  - `[KB:DataDiscrepancy]` - Discrepancies between aggregated summary files and the sum of their weekly parts indicate a bug in the aggregation or scoring process.
  - `[KB:DefensiveDebugging]` - When a script produces nonsensical results, the issue is likely a logical bug in the script's data handling, not the underlying model.
- Code Health: All linting and formatting issues were resolved. All tests pass. Docs build successfully.
- Decisions: `[PRD-decision:2025-10-09]`

## Handoff

- Stopping Point: The requested analysis for 2024 and 2025 is complete, and the pipeline has been refactored. The codebase is in a clean and stable state.
- Next Immediate Task: The user's request is complete. The next logical step is to analyze the generated Week 7 picks and prepare for the weekly operational run.
- Known Issues: None.


---

### 2025-10-10

#### Session 01

---
date: 2025-10-10
branch: main
task: [IMPL-task:32, IMPL-task:33] - Implement Advanced Features (Rushing Analytics and Situational Efficiency)
---

## Wins

- Implemented `third_down_conversion_rate` feature, as other requested advanced rushing analytics were already present.
- Integrated the new feature into the full aggregation pipeline (`team-game` -> `team-season` -> `opponent-adjusted`).
- Fixed all test failures that arose from the new feature implementation, including data errors in test cases and indentation issues.
- Successfully retrained the ensemble models with the updated feature set.
- Updated the project documentation (`decision_log.md`, `feature_catalog.md`, `feature_engineering_plan.md`) to reflect the changes.

## Blockers

- The initial model evaluation after adding the new feature showed a significant drop in the number of bets placed, which was traced back to an increase in the variance of the model's predictions.
- Several `IndentationError` and `KeyError` issues were encountered during development, requiring careful debugging of the data pipeline and test cases.

## Artifacts & Links

- Decisions: `[PRD-decision:2025-10-10]`
- Code Health: All checks passed (Ruff format, Ruff check, Pytest, MkDocs build).

## Handoff

- **Stopping Point:** The advanced features have been implemented, and the documentation has been updated. The codebase is in a clean and stable state.
- **Next Immediate Task:** The confidence thresholds (`--spread-std-dev-threshold` and `--total-std-dev-threshold`) may need to be re-tuned to account for the higher variance of the new model and increase the number of bets placed.
- **Known Issues:** None.


---

#### Session 02

---
date: 2025-10-10
branch: main
task: "[IMPL-task:MLOPS-01] - Begin MLOps reorientation and update documentation."
---

## Wins

- Updated the project roadmap (`docs/planning/roadmap.md`) to accurately reflect all completed work and set the next development priorities.
- Re-tuned the model's confidence thresholds after the recent addition of advanced features, identifying new optimal values (`spread_std_dev=2.0`, `total_std_dev=1.5`) to balance accuracy and bet volume.
- Began the MLOps reorientation by adding `mlflow`, `hydra-core`, `hydra-optuna-sweeper`, and `optuna` as core project dependencies.
- Created the `conf/` directory for future Hydra configurations.
- Successfully refactored the main training script (`src/cfb_model/models/train_model.py`) to integrate MLflow for experiment tracking, using nested runs to log parameters, metrics, and artifacts for each model in the ensemble.
- Updated all relevant documentation (`decision_log.md`, `kb_overview.md`, and framework guides) to reflect these changes.

## Blockers

- The initial health check failed due to a dependency conflict I introduced between `optuna` and `hydra-optuna-sweeper`. This was resolved by downgrading the `optuna` version in `pyproject.toml`.
- A second health check failed due to a `NameError` and a missing docstring in the refactored training script. Both issues were fixed.

## Artifacts & Links

- **Decisions**: `[PRD-decision:2025-10-10]` (MLOps Reorientation), `[PRD-decision:2025-10-10]` (Confidence Thresholds)
- **Knowledge Base**: `[KB:MLflowNestedRuns]`
- **Code**: `src/cfb_model/models/train_model.py`, `pyproject.toml`
- **Docs**: `docs/planning/roadmap.md`, `docs/guides/scikit-learn_guide.md`, `docs/guides/PyTorch_guide.md`, `docs/guides/Tensorflow_guide.md`, `docs/guides/MLOps_Integration_Guide.md`

## Handoff

- **Stopping Point**: The first phase of the MLOps integration (MLflow) is complete and the codebase is stable and passes all health checks.
- **Next Immediate Task**: Continue the MLOps integration by refactoring the training script to use **Hydra** for configuration management, replacing `argparse` with `.yaml` configuration files.
- **Known Issues**: None.


---

### 2025-10-11

#### Session 01

---
date: 2025-10-11
branch: main
task: [IMPL-task:35] - Refactor hyperparameter optimization script to use Hydra and Optuna.
---

## Wins

- Refactored `scripts/optimize_hyperparameters.py` to use Hydra for configuration and Optuna for optimization.
- Created Hydra configuration files for Ridge and RandomForest models (`conf/optimize_ridge.yaml`, `conf/optimize_random_forest.yaml`).
- Added `hydra-joblib-launcher` dependency.
- Debugged and fixed `NaN` value errors in the optimization script.
- Updated project documentation to reflect the new MLOps stack.

## Blockers

- The Hydra Optuna sweeper had issues with the search space defined in the config file when using multirun.
- Shell command syntax errors when passing complex arguments.
- `ValueError: Input X contains NaN` in the optimization script.

## Artifacts & Links

- Learnings: `[KB:HydraMultiRunConfig]` - When using Hydra's multirun with the Optuna sweeper, the search space might need to be passed via the command line instead of being defined in the config file.
- Learnings: `[KB:ShellQuoting]` - Complex shell command arguments with parentheses need to be properly quoted to avoid syntax errors.
- Learnings: `[KB:ImputeNaNs]` - `NaN` values in the input data for scikit-learn models can be handled by using an imputer or by filling them with a specific value (e.g., 0).

## Handoff

- Stopping Point: The hyperparameter optimization script has been refactored, but is not yet successfully running with the Optuna sweeper.
- Next Immediate Task: Resolve the remaining issues with the Hydra Optuna sweeper to run the hyperparameter optimization successfully. Then, run the optimization for both spread and total models, analyze the results, and update the default model parameters.
- Known Issues: The Hydra Optuna sweeper is not working as expected with the current configuration.
- Next Session Context: The project has a refactored hyperparameter optimization script that needs further debugging to work with the Hydra Optuna sweeper.


---

