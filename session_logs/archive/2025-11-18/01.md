---
date: 2025-11-18
branch: main
task: [IMPL-task:MLOPS-MCP] - Harden artifacts outputs and add MLflow MCP server
---

# TL;DR (≤5 lines)

- Re-trained 2024 legacy ensembles on cached data and regenerated the week 12 prediction slate for 2025.
- Verified Hydra/Optuna + MLflow logging paths and documented the Dockerized MLflow stack plus MCP server workflow.
- Added docs + config improvements (data-root env fallback, port overrides) so future assistants can attach via MCP.
- MCP server instructions drafted; containerized MLflow UI is running on localhost for reviews.

**tags:** ["mlops","infra","docs","predictions"]

## Wins

- Trained the 2019/21/22/23 → 2024 spread/total ensembles via `uv run python -m src.models.train_model …` with metrics stored under `artifacts/models/2024/metrics/`.
- Generated fresh 2025 week 12 bets using the cached data root and latest artifacts, confirming the prediction CSV in `artifacts/reports/2025/predictions/CFB_week12_bets.csv`.
- Created a Dockerized MLflow stack with configurable ports plus a full MCP how-to (`docs/operations/mlflow_mcp.md`) so AI tooling can query traces via MCP.
- Validated Hydra/Optuna integration with a sweep trial (`scripts/optimize_hyperparameters.py`) writing to `artifacts/outputs/2025-11-18/**`.

## Blockers

- Docker initially failed to bind port 5000 for MLflow; resolved via the new `MLFLOW_PORT` override. No other active blockers.

## Artifacts & Links

- Metrics: `artifacts/models/2024/metrics/model_eval_2024.csv`
- Predictions: `artifacts/reports/2025/predictions/CFB_week12_bets.csv`
- Infra Docs: `docker/mlops/docker-compose.yml`, `docs/operations/mlflow_mcp.md`
- Runs: `artifacts/mlruns/` and `artifacts/outputs/2025-11-18/08-56-34`

## Handoff

- Stopping Point: Dockerized MLflow + MCP instructions are live; week 12 outputs generated with refreshed ensembles.
- Next Immediate Task: Investigate elevated ensemble RMSE/MAE (feature scaling, target windows) and prep Sprint 5 monitoring tasks.
- Known Issues: Spread/total RMSE remains high vs. baseline; root-cause analysis still pending.
- Next Session Context: Use the running MLflow UI and MCP server to inspect recent runs, compare against baselines, and action modeling improvements.
