---
date: 2025-11-20
branch: main
task: [IMPL-task:MODEL-DEV] - Diagnose and fix numerical instability in spread model
---

# TL;DR (â‰¤5 lines)
- Created a diagnostic script to investigate numerical instability (`RuntimeWarning`s) in the linear models.
- The analysis revealed two root causes: `NaN` values in adjusted features and perfect multicollinearity (infinite VIF scores) in the feature set, particularly from `_last_` recency features.
- A new "stable" training script was created to handle these issues by dropping `NaN` rows and iteratively removing features with VIF > 100.
- Surprisingly, the `RuntimeWarning`s *persisted* even after these fixes, indicating a more fundamental data quality issue (likely `inf` or extreme outliers) that is not being caught.
- Concluded that the problem lies deep within the feature engineering pipeline itself, and the next step must be a code-level review of that process, not further modeling attempts.

**tags:** ["modeling", "spread-model", "feature-engineering", "validation", "failure-analysis", "numerical-instability", "EDA", "VIF"]

## Wins
- Successfully diagnosed the presence of `NaN` values and severe multicollinearity in the feature set.
- Created a robust diagnostic script (`scripts/diagnose_feature_instability.py`) that can be used in the future.
- Created a "stable" training script that correctly handles `NaN`s and uses VIF to prune collinear features.

## Blockers
- The numerical instability in the linear models remains unresolved, blocking any reliable model evaluation. The root cause is deeper and more subtle than simple multicollinearity or missing values.

## Analysis of Failure
The final, most robust attempt involved:
1.  **Dropping `NaN`s:** Explicitly removing rows with `NaN` feature values.
2.  **VIF Pruning:** Iteratively removing features with a Variance Inflation Factor (VIF) greater than 100.
3.  **Scaling:** Using `StandardScaler` on the data.

Even with all three of these measures in place, the `RuntimeWarning: divide by zero, overflow, invalid value in matmul` errors persisted. This proves that the issue is not something that can be fixed with standard preprocessing at the modeling stage. The problem lies in the data generation process itself. It is likely that `inf` values or extreme outliers are being generated in the feature engineering code and are not being handled correctly.

## Handoff
- **Stopping Point:** All standard methods for addressing data instability at the modeling stage have been exhausted and have failed. The problem has been isolated to the feature engineering pipeline.
- **Next Immediate Task:** A deep-dive, code-level review of the feature engineering pipeline (`src/models/features.py` and its dependencies) is required. The goal is to find where `inf` values or extreme outliers are being generated and to fix the root cause.
- **Next Session Context:** Do not attempt to train any more models until the feature generation code has been audited and fixed. The diagnostic script (`scripts/diagnose_feature_instability.py`) can be used to verify that the data quality issues have been resolved. The experimental scripts (`train_stable_spread_model.py`, `validate_stable_spread_model.py`, etc.) should be deleted to keep the repository clean.
