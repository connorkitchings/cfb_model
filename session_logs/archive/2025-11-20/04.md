---
date: 2025-11-20
branch: main
task: [IMPL-task:MODEL-DEV] - Final attempt to stabilize spread model
---

# TL;DR (â‰¤5 lines)
- Made a final, multi-pronged attempt to stabilize the linear models by fixing `NaN` propagation in the feature engineering code, dropping `NaN` rows, pruning high-VIF features, and scaling the data.
- Despite these efforts, the `RuntimeWarning`s (divide by zero, overflow) persisted, proving the root cause is a deep and subtle data quality issue.
- Concluded that the problem cannot be solved at the modeling stage and requires a manual, code-level audit of the feature engineering pipeline in `src/features/core.py`.
- All experimental scripts and configuration changes from this session have been reverted to leave the repository in a clean state.
- The key learning is that future modeling work is blocked until the data generation process itself is fixed.

**tags:** ["modeling", "spread-model", "feature-engineering", "failure-analysis", "numerical-instability", "data-quality"]

## Final Analysis
This session was a deep dive into a persistent numerical instability issue. The final, most robust attempt to fix it involved:
1.  **Fixing `NaN` propagation:** Corrected the opponent-adjustment logic in `src/features/core.py` to use `np.nansum`, preventing `NaN`s from spreading during the calculation.
2.  **Aggressive Data Cleaning:** Implemented a new training script that explicitly dropped any rows containing `NaN`s.
3.  **VIF Pruning:** The script also iteratively removed features with a Variance Inflation Factor (VIF) greater than 100. This successfully identified and removed several highly collinear features.
4.  **Scaling:** The script used `StandardScaler` to normalize the feature set.

Despite all of these interventions, the `RuntimeWarning`s persisted. This is a strong conclusion that the problem is not simple multicollinearity or missing values. It is almost certainly caused by the generation of extreme, non-physical values or `inf`s within the feature engineering code that are not being caught by the current diagnostic tools.

## Handoff
- **Stopping Point:** This line of investigation is complete. The problem has been isolated to the feature engineering code, and further attempts to fix it at the modeling stage will be fruitless.
- **Next Immediate Task:** The next session must be a dedicated, manual debugging session of the feature aggregation logic in `src/features/core.py`.
- **Recommendation for Next Session:**
    1.  Start with the `debug_feature_pipeline.py` script created in this session.
    2.  Instead of just checking for `inf` and `NaN` at the end of each function, add `print(df.describe().transpose())` and checks for `inf` *inside* the loops and calculations within `aggregate_team_game` and `aggregate_team_season`.
    3.  Trace the lineage of a single, problematic feature (like `home_off_rush_ypp_last_3`) from its raw components to its final value to see where the extreme values are introduced.
    4.  Once the source is found, implement a fix (e.g., clipping values, adding a larger epsilon, or reformulating the metric).
